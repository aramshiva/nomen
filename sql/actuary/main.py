"""
WARNING:
THIS CODE IS PARTIALLY GENERATED BY AI, 
SPECIFICALLY FOR THE PURPOSE OF CHANGING 
THE MAIN.PY FILE TO INCLUDE ACTUARY DATA 
FOR THIS SCRIPT INSTEAD
"""

import mysql.connector
import os
import time
import argparse
import csv
from datetime import timedelta
from dotenv import load_dotenv

load_dotenv('.env.local')

def create_db(db_config):
    """Create database and actuary table if they don't exist"""
    db_config['database'] = os.getenv('DATABASE_NAM')    
    print(f"Connecting to MySQL server at {db_config['host']}...")
    
    conn = mysql.connector.connect(**db_config)
    c = conn.cursor()
    
    c.execute('''
        CREATE TABLE IF NOT EXISTS `actuary` (
            `id` int(11) NOT NULL AUTO_INCREMENT,
            `gender` enum('M','F') DEFAULT NULL,
            `year` int(11) DEFAULT NULL,
            `age` int(11) DEFAULT NULL,
            `probability_of_death` float DEFAULT NULL,
            PRIMARY KEY (`id`)
        ) ENGINE=InnoDB DEFAULT CHARSET=latin1 COLLATE=latin1_swedish_ci
    ''')
    conn.commit()
    print("Actuary table created successfully.")
    return conn

def process_csv_files(folder_path, db_conn, batch_size):
    """Process actuarial CSV files and insert data into database"""
    csv_files = [
        'F-1900-2010.csv',
        'F-2011-2090.csv', 
        'M-1900-2010.csv',
        'M-2011-2090.csv'
    ]
    
    processed_rows = 0
    total_time = 0
    batch_count = 0
    
    print(f"Processing CSV files with batch size: {batch_size}")
    
    for csv_file in csv_files:
        file_path = os.path.join(folder_path, csv_file)
        if not os.path.exists(file_path):
            print(f"Warning: File {csv_file} not found, skipping...")
            continue
            
        gender = csv_file[0]
        batch_data = []
        file_start_time = time.time()
        
        print(f"Processing {csv_file}...")
        
        with open(file_path, 'r', encoding='utf-8') as f:
            csv_reader = csv.reader(f)
            header = next(csv_reader, None)
            
            for row in csv_reader:
                if len(row) >= 3:
                    try:
                        year = int(row[0])
                        age = int(row[1])
                        probability = float(row[2])
                        
                        batch_data.append((gender, year, age, probability))
                        processed_rows += 1
                        
                        if len(batch_data) >= batch_size:
                            batch_start_time = time.time()
                            insert_batch(db_conn, batch_data)
                            batch_time = time.time() - batch_start_time
                            total_time += batch_time
                            batch_count += 1
                            
                            print_progress(processed_rows, gender, year, age, batch_time)
                            batch_data = []
                            
                    except (ValueError, IndexError) as e:
                        print(f"Skipping invalid row in {csv_file}: {row} - {e}")
                        continue
        
        if batch_data:
            batch_start_time = time.time()
            insert_batch(db_conn, batch_data)
            batch_time = time.time() - batch_start_time
            total_time += batch_time
            batch_count += 1
            
            print_progress(processed_rows, gender, year, age, batch_time)
        
        file_time = time.time() - file_start_time
        print(f"Completed processing {csv_file} in {timedelta(seconds=file_time)}")
    
    if batch_count > 0:
        avg_batch_time = total_time / batch_count
        print("\nPerformance Summary:")
        print(f"Total processing time: {timedelta(seconds=total_time)}")
        print(f"Average batch processing time: {timedelta(seconds=avg_batch_time)}")
        print(f"Total rows processed: {processed_rows}")
        if total_time > 0:
            print(f"Rows per second: {processed_rows / total_time:.2f}")

def insert_batch(conn, batch_data):
    """Insert batch of actuarial data into database"""
    c = conn.cursor()
    
    query = '''
        INSERT INTO actuary (gender, year, age, probability_of_death) 
        VALUES (%s, %s, %s, %s)
    '''
    
    c.executemany(query, batch_data)
    conn.commit()

def print_progress(current, gender, year, age, batch_time=None):
    """Print progress information"""
    gender_full = "Female" if gender == "F" else "Male"
    
    progress_msg = f"Processed {current} rows (Latest: {gender_full}, Year {year}, Age {age})"
    if batch_time is not None:
        progress_msg += f" - Batch inserted in {batch_time:.2f}s"
    
    print(progress_msg)

def parse_arguments():
    """Parse command line arguments"""
    parser = argparse.ArgumentParser(description='Import actuarial data into MySQL database')
    parser.add_argument('--batch-size', type=int, default=10000,
                        help='Number of records to insert in a single batch (default: 10000)')
    return parser.parse_args()

def main():
    start_time = time.time()
    
    args = parse_arguments()
    
    if not os.getenv('DATABASE_HST'):
        load_dotenv()
        
    db_config = {
        'user': os.getenv('DATABASE_USR'),
        'password': os.getenv('DATABASE_PWD'),
        'host': os.getenv('DATABASE_HST'),
        'raise_on_warnings': True
    }
    
    folder_path = os.path.join(os.path.dirname(__file__), '..', 'actuary', 'data')
    if not os.path.exists(folder_path):
        print(f"Error: Actuary data folder not found at {folder_path}")
        print("Please ensure the actuary/data folder exists with the CSV files.")
        return
    
    try:
        conn = create_db(db_config)
    except mysql.connector.Error as e:
        print(f"Error creating database: {e}")
        print(f"Attempted to connect to: {db_config['host']}")
        return
    
    try:
        process_csv_files(folder_path, conn, args.batch_size)
    except (mysql.connector.Error, FileNotFoundError, IOError) as e:
        print("Error processing files:", e)
    
    total_time = time.time() - start_time
    print(f"\nTotal actuarial data import time: {timedelta(seconds=total_time)}")
    
    print("Actuarial data import completed successfully!")
    print("Closing connection...")
    conn.close()
    print("Connection closed.")
    print("If you haven't already, please run the main.py (in the folder outside of this) script to import names data into the database.")
    print("If you have, your databases should now be ready for use with nomen.")
    print("Please refer to the README to setup the app locally. :)")
    print("Thank you for using/contributing Nomen! I hope you enjoy it!")

if __name__ == '__main__':
    main()